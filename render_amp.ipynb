{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "This notebook contains code that I used to reamp the GOAT dataset. The basic sound of an electric guitar can be modeled using an amplifier (to model the distortion) and a impulse response (IR) of the speaker cabinet. I personally used the Neural Amp Modeler (NAM) for the amplifier rendering, and the cabinet sim of the NeuralDSP Achetype Nolly plugin for the cabinet IRs. The parameters for each are randomised, allowing for a large amount of variance in the sounds. This code can be modified as well to use any plugins you want!\n",
    "\n",
    "If you would like to use the NAM, you will need our NAM profile dataset as well (available from Zenodo upon acceptance of our corresponding paper). This dataset contains roughly 7000 publically available NAM profiles covering a large range of different amplifiers and tones, from clean to super distorted. \n",
    "\n",
    "We used a CSV file with the alignment results to select for only data which has a f_measure_fine value of .75 or higher to ensure that we only used data with high alignment accuracy. This CSV will be made available soon, but in the meantime you can comment out the relevant lines (marked with ###)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pedalboard import Pedalboard, Reverb, load_plugin\n",
    "from pedalboard.io import AudioFile\n",
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from IPython.display import Audio\n",
    "\n",
    "SAMPLE_RATE = 44100\n",
    "BUFFER_SIZE = 128\n",
    "\n",
    "# REPLACE THESE PATHS WITH PATHS TO YOUR OWN PLUGINS AND NAM DATASET\n",
    "nam_path = '/Library/Audio/Plug-Ins/VST3/NeuralAmpModeler.vst3'\n",
    "nolly_path = '/Library/Audio/Plug-Ins/Components/Archetype Nolly X.component'\n",
    "presets_path = '/Documents/PhD/Datasets/NAMProfileDataset/vstpresets'\n",
    "\n",
    "nam_presets = os.listdir(presets_path)\n",
    "remove_name = \".DS_Store.vstpreset\"\n",
    "if remove_name in nam_presets:\n",
    "    nam_presets.remove(remove_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic_types = ['Dynamic 57', 'Dynamic 421', 'Condenser 184', 'Condenser 414', 'Ribbon 121', 'Ribbon 160', 'Dynamic 57', 'Dynamic 421', 'Condenser 184', 'Condenser 414', 'Ribbon 121', 'Ribbon 160']\n",
    "room_prob = 0.25\n",
    "def get_nolly():\n",
    "    nolly = load_plugin(nolly_path)\n",
    "    nolly.active_amp_section = False\n",
    "    #nolly.active_pre_fx_section = False\n",
    "    nolly.active_eq_section = False\n",
    "    #nolly.active_post_fx_section = False\n",
    "    nolly.rhythm_amp_cab_mic_l_type = mic_types[random.randint(0, len(mic_types)-1)]\n",
    "    nolly.cab_l_position = random.uniform(0, 1)\n",
    "    nolly.cab_l_distance = random.uniform(0, 1)\n",
    "    nolly.cab_l_phase = bool(random.randint(0, 1))\n",
    "    if random.uniform(0, 1) < room_prob:\n",
    "        nolly.room_l_active = True\n",
    "        nolly.room_l_send = random.randint(-10, 0)\n",
    "    else:\n",
    "        nolly.room_l_active = False\n",
    "    return nolly\n",
    "\n",
    "def get_nam():\n",
    "    nam = load_plugin(nam_path)\n",
    "    preset_path = os.path.join(presets_path, nam_presets[random.randint(0, len(nam_presets)-1)])\n",
    "    nam.load_preset(preset_path)\n",
    "    return nam\n",
    "\n",
    "nam_t = get_nam()\n",
    "nolly_t = get_nolly()\n",
    "board = Pedalboard([nam_t, nolly_t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contruct list of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "goat_path = 'ENTER DATASET PATH'\n",
    "csv_path = 'ENTER CSV PATH' ###\n",
    "df = pd.read_csv(csv_path) ###\n",
    "\n",
    "wav_files = []\n",
    "for root, dirs, files in os.walk(goat_path):\n",
    "    for f in files:\n",
    "        if f.endswith('.wav') and not f.endswith('_gp.wav') and not f.endswith('_gp_di.wav'):\n",
    "            path_audio = os.path.join(root, f)\n",
    "            path_midi = os.path.join(root, f).replace('.wav', '_fine_aligned.mid')\n",
    "\n",
    "            search_path = path_audio.replace(goat_path, '') ###\n",
    "            matching_rows = df[df['audio_path'].str.contains(search_path, na=False, regex=False)] ###\n",
    "\n",
    "            \n",
    "            if len(matching_rows) != 1: ###\n",
    "                continue ###\n",
    "\n",
    "            f_measure_fine_value = matching_rows['f_measure_fine'].values[0]  ###\n",
    "            if f_measure_fine_value < 0.75: ###\n",
    "                continue ###\n",
    "            \n",
    "            # NOTE: The final published dataset may haev a different structure, so this will need to be updated\n",
    "            # This is essentially just selected specific songs to be in the test split\n",
    "            if 'Dani' in path_audio or 'Lithium' in path_audio or 'Reptilia' in path_audio:\n",
    "                wav_files.append(('test', path_audio, path_midi))\n",
    "            else:\n",
    "                wav_files.append(('train', path_audio, path_midi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Render data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [55:21<00:00, 14.96s/it] \n"
     ]
    }
   ],
   "source": [
    "goat_amp_path_test = 'ENTER YOUR DESIRED TEST PATH HERE'\n",
    "goat_amp_path_train = 'ENTER YOUR DESIRED TRAIN PATH HERE'\n",
    "\n",
    "i = 0\n",
    "for f in tqdm(wav_files):\n",
    "    split, path_audio, path_midi = f\n",
    "    audio, sample_rate = librosa.load(path_audio, sr=None, mono=True)\n",
    "    board = Pedalboard([get_nam(), get_nolly()])\n",
    "\n",
    "    processed_audio = board(audio, sample_rate)\n",
    "    processed_audio_name = hashlib.md5((path_audio + str(i)).encode()).hexdigest() + '.wav'\n",
    "    i += 1\n",
    "    if split == 'test':\n",
    "        processed_audio_path = os.path.join(goat_amp_path_test, processed_audio_name)\n",
    "        midi_path = processed_audio_path.replace('.wav', '.mid')\n",
    "        try:\n",
    "            os.system(f'cp \"{path_midi}\" \"{midi_path}\"')\n",
    "        except:\n",
    "            continue\n",
    "        sf.write(processed_audio_path, processed_audio, sample_rate)\n",
    "    elif split == 'train':\n",
    "        processed_audio_path = os.path.join(goat_amp_path_train, processed_audio_name)\n",
    "        midi_path = processed_audio_path.replace('.wav', '.mid')\n",
    "        try:\n",
    "            os.system(f'cp \"{path_midi}\" \"{midi_path}\"')\n",
    "        except:\n",
    "            continue\n",
    "        sf.write(processed_audio_path, processed_audio, sample_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
